{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upper-danger",
   "metadata": {},
   "source": [
    "# SMS Spam classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-degree",
   "metadata": {},
   "source": [
    "Run the following cell to complete data and english language spaCy model load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "potential-persian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"spam_data.csv\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "with nlp.disable_pipes():\n",
    "    doc_vectors = np.array([nlp(text).vector for text in data.Message])\n",
    "\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "physical-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y list shape: (5572,) \n",
      "y_train list shape: (3900,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=doc_vectors\n",
    "y=data.Category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=388,\n",
    "                                                        stratify=y, shuffle=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print(f\"y list shape: {y.shape} \\ny_train list shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The actor or task with ID ffffffffffffffff6b98451801000000 cannot be scheduled right now. It requires {CPU: 1.000000} for placement, but this node only has remaining {node:192.168.0.12: 1.000000}, {GPU: 1.000000}, {object_store_memory: 1.513672 GiB}, {memory: 4.492188 GiB}. In total there are 0 pending tasks and 4 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n"
     ]
    }
   ],
   "source": [
    "# Importing models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mlp = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "print(\"Starting grid search\")\n",
    "\n",
    "# parameter_space = {\n",
    "#     'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "\n",
    "# parameter_space = {'bootstrap': [True, False],\n",
    "#  'max_depth': [10, 30, 50, 70, 90, None],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10],\n",
    "#  'n_estimators': [200, 600, 1000, 1400, 1800]}\n",
    "\n",
    "# parameter_space = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2','l1']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "parameter_space = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tune_sklearn import TuneGridSearchCV\n",
    "\n",
    "clf = TuneGridSearchCV(mlp, parameter_space, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "model=clf\n",
    "print(f\"------------Model: {model}------------\")\n",
    "print(f\"Model score: {model.score(X_test,y_test)*100:.3f}%\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf_splits = skf.get_n_splits(X_train, y_train)\n",
    "\n",
    "skf_scores=[]\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    X_train_fold , X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    model.fit(X_train_fold, y_train_fold) \n",
    "    skf_scores.append(model.score(X_test_fold,y_test_fold))\n",
    "\n",
    "cv_scores_macro = cross_val_score(model, X, y, cv=skf_splits, scoring='f1_macro')\n",
    "cv_scores_micro = cross_val_score(model, X, y, cv=skf_splits, scoring='f1_micro')\n",
    "\n",
    "print(f\"Cross-validation f1-macro score: {np.mean(cv_scores_macro) * 100:.3f}%\", )\n",
    "print(f\"Cross-validation f1-micro score: {np.mean(cv_scores_micro) * 100:.3f}%\", )\n",
    "print(f\"Stratified k-fold score: {np.mean(skf_scores) * 100:.3f}%\\n\", )\n",
    "plt.figure()\n",
    "plt.plot(model.loss_curve_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-validity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
